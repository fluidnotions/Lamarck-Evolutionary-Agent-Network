"""
State management for HVAS Mini.

Defines the shared state structure used by LangGraph and all agents.
"""

from typing import TypedDict, Dict, List, Optional, Any
from pydantic import BaseModel, Field
from datetime import datetime

# Import hierarchy structure
try:
    from lean.hierarchy.structure import AgentHierarchy
except ImportError:
    AgentHierarchy = None


class AgentMemory(BaseModel):
    """Individual agent memory record.

    Stored in ChromaDB and retrieved for context during generation.
    """

    content: str = Field(..., description="The generated content to remember")
    topic: str = Field(..., description="Topic this content relates to")
    score: float = Field(..., ge=0.0, le=10.0, description="Quality score (0-10)")
    timestamp: str = Field(
        default_factory=lambda: datetime.now().isoformat(),
        description="ISO timestamp of creation",
    )
    embeddings: Optional[List[float]] = Field(
        default=None, description="Vector embeddings for similarity search"
    )
    retrieval_count: int = Field(
        default=0, description="Number of times this memory has been retrieved"
    )

    class Config:
        """Pydantic configuration."""

        json_schema_extra = {
            "example": {
                "content": "Machine learning is a subset of artificial intelligence...",
                "topic": "machine learning basics",
                "score": 8.5,
                "timestamp": "2024-03-15T10:30:00",
                "retrieval_count": 3,
            }
        }


class BlogState(TypedDict):
    """Shared state for blog generation workflow.

    This state is passed between nodes in the LangGraph workflow.
    All agents read from and write to this shared state.
    """

    # Content generated by agents
    topic: str  # Input topic for blog post
    intro: str  # Introduction section
    body: str  # Main body section
    conclusion: str  # Conclusion section

    # Evaluation scores (0-10 scale)
    scores: Dict[str, float]  # {"intro": 8.5, "body": 7.0, "conclusion": 9.0}

    # Memory and evolution tracking
    retrieved_memories: Dict[
        str, List[str]
    ]  # Memories used by each agent
    parameter_updates: Dict[str, Dict[str, float]]  # Parameter changes per agent

    # Metadata
    generation_id: str  # Unique ID for this generation run
    timestamp: str  # ISO timestamp of generation start
    stream_logs: List[str]  # Activity logs for visualization

    # NEW: Concurrency tracking
    agent_timings: Dict[str, Dict[str, float]]  # {agent: {start, end, duration}}
    layer_barriers: List[Dict[str, float]]  # [{layer_id, agents, wait_time}]

    # NEW: Weight tracking (M2)
    agent_weights: Dict[str, Dict[str, float]]  # {agent: {peer: trust_weight}}
    weight_history: List[Dict[str, float]]  # [{generation, agent, peer, weight, delta}]

    # NEW: Reasoning patterns (V2 architecture)
    intro_reasoning: str  # <think> content from intro agent
    body_reasoning: str  # <think> content from body agent
    conclusion_reasoning: str  # <think> content from conclusion agent
    reasoning_patterns_used: Dict[str, int]  # {role: count} - patterns retrieved
    domain_knowledge_used: Dict[str, int]  # {role: count} - knowledge items retrieved
    generation_number: int  # Which generation in the sequence (for M2)

    # NEW: Ensemble competition results
    intro_ensemble_results: List[Dict[str, Any]]  # All intro agent results with scores
    body_ensemble_results: List[Dict[str, Any]]  # All body agent results with scores
    conclusion_ensemble_results: List[Dict[str, Any]]  # All conclusion agent results with scores
    intro_winner_id: str  # ID of winning intro agent
    body_winner_id: str  # ID of winning body agent
    conclusion_winner_id: str  # ID of winning conclusion agent


class AgentOutput(TypedDict):
    """Output from an agent with metadata."""
    content: str
    confidence: float  # 0.0-1.0
    metadata: Dict[str, Any]  # Additional context


class HierarchicalState(BlogState):
    """Extended state for hierarchical execution.

    Adds fields for managing 3-layer hierarchy with coordinator,
    content agents, and specialists.
    """

    # Hierarchy instance
    hierarchy: Any  # AgentHierarchy type (avoid circular import)

    # Execution tracking
    current_layer: int  # Which layer is executing (1-3)
    current_pass: int  # Which refinement pass (for M8)
    max_passes: int  # Maximum refinement passes

    # Layer outputs with confidence
    layer_outputs: Dict[int, Dict[str, AgentOutput]]
    # {1: {"coordinator": AgentOutput}, 2: {"intro": AgentOutput, ...}, 3: {...}}

    # Coordinator state
    coordinator_intent: str  # High-level parsed intent
    coordinator_critique: Dict[str, str]  # {agent_role: feedback}
    revision_requested: bool  # Whether refinement is needed
    quality_threshold_met: bool  # Whether quality is acceptable

    # Pass tracking for closed-loop refinement
    pass_history: List[Dict[str, Any]]
    # [{pass: 1, scores: {...}, outputs: {...}}, ...]


def create_initial_state(topic: str) -> BlogState:
    """Create initial state for a new blog generation.

    Args:
        topic: The topic to write about

    Returns:
        Initialized BlogState with empty values
    """
    import uuid

    return BlogState(
        topic=topic,
        intro="",
        body="",
        conclusion="",
        scores={},
        retrieved_memories={},
        parameter_updates={},
        generation_id=str(uuid.uuid4()),
        timestamp=datetime.now().isoformat(),
        stream_logs=[],
        agent_timings={},
        layer_barriers=[],
        agent_weights={
            "intro": {},
            "body": {},
            "conclusion": {},
        },
        weight_history=[],
        intro_reasoning="",
        body_reasoning="",
        conclusion_reasoning="",
        reasoning_patterns_used={},
        domain_knowledge_used={},
        generation_number=0,
        intro_ensemble_results=[],
        body_ensemble_results=[],
        conclusion_ensemble_results=[],
        intro_winner_id="",
        body_winner_id="",
        conclusion_winner_id="",
    )


def create_hierarchical_state(topic: str) -> HierarchicalState:
    """Create initial hierarchical state for a new blog generation.

    Args:
        topic: The topic to write about

    Returns:
        Initialized HierarchicalState with empty hierarchical values
    """
    base_state = create_initial_state(topic)

    # Add hierarchical fields
    hierarchical_fields = {
        "hierarchy": AgentHierarchy() if AgentHierarchy else None,
        "current_layer": 0,
        "current_pass": 1,
        "max_passes": 3,
        "layer_outputs": {1: {}, 2: {}, 3: {}},
        "coordinator_intent": "",
        "coordinator_critique": {},
        "revision_requested": False,
        "quality_threshold_met": False,
        "pass_history": [],
    }

    return {**base_state, **hierarchical_fields}  # type: ignore


def validate_state(state: BlogState) -> bool:
    """Validate that state has all required keys.

    Args:
        state: The state to validate

    Returns:
        True if valid, raises ValueError otherwise
    """
    required_keys = [
        "topic",
        "intro",
        "body",
        "conclusion",
        "scores",
        "retrieved_memories",
        "parameter_updates",
        "generation_id",
        "timestamp",
        "stream_logs",
        "agent_timings",
        "layer_barriers",
        "agent_weights",
        "weight_history",
    ]

    missing = [key for key in required_keys if key not in state]
    if missing:
        raise ValueError(f"State missing required keys: {missing}")

    return True
